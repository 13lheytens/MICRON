{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularGraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, N_fingerprint, dim, layer_hidden, device):\n",
    "        super(MolecularGraphNeuralNetwork, self).__init__()\n",
    "        self.embed_fingerprint = nn.Embedding(N_fingerprint, dim)\n",
    "        self.W_fingerprint = nn.ModuleList([nn.Linear(dim, dim)\n",
    "                                            for _ in range(layer_hidden)])\n",
    "        self.device = device\n",
    "        self.layer_hidden = layer_hidden\n",
    "\n",
    "    def pad(self, matrices, pad_value):\n",
    "        \"\"\"Pad the list of matrices\n",
    "        with a pad_value (e.g., 0) for batch processing.\n",
    "        For example, given a list of matrices [A, B, C],\n",
    "        we obtain a new matrix [A00, 0B0, 00C],\n",
    "        where 0 is the zero (i.e., pad value) matrix.\n",
    "        \"\"\"\n",
    "        shapes = [m.shape for m in matrices]\n",
    "        M, N = sum([s[0] for s in shapes]), sum([s[1] for s in shapes])\n",
    "        zeros = torch.FloatTensor(np.zeros((M, N))).to(self.device)\n",
    "        pad_matrices = pad_value + zeros\n",
    "        i, j = 0, 0\n",
    "        for k, matrix in enumerate(matrices):\n",
    "            m, n = shapes[k]\n",
    "            pad_matrices[i:i+m, j:j+n] = matrix\n",
    "            i += m\n",
    "            j += n\n",
    "        return pad_matrices\n",
    "\n",
    "    def update(self, matrix, vectors, layer):\n",
    "        hidden_vectors = torch.relu(self.W_fingerprint[layer](vectors))\n",
    "        return hidden_vectors + torch.mm(matrix, hidden_vectors)\n",
    "\n",
    "    def sum(self, vectors, axis):\n",
    "        sum_vectors = [torch.sum(v, 0) for v in torch.split(vectors, axis)]\n",
    "        return torch.stack(sum_vectors)\n",
    "\n",
    "    def mean(self, vectors, axis):\n",
    "        mean_vectors = [torch.mean(v, 0) for v in torch.split(vectors, axis)]\n",
    "        return torch.stack(mean_vectors)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        \"\"\"Cat or pad each input data for batch processing.\"\"\"\n",
    "        fingerprints, adjacencies, molecular_sizes = inputs\n",
    "        fingerprints = torch.cat(fingerprints)\n",
    "        adjacencies = self.pad(adjacencies, 0)\n",
    "\n",
    "        \"\"\"GNN layer (update the fingerprint vectors).\"\"\"\n",
    "        fingerprint_vectors = self.embed_fingerprint(fingerprints)\n",
    "        for l in range(self.layer_hidden):\n",
    "            hs = self.update(adjacencies, fingerprint_vectors, l)\n",
    "            # fingerprint_vectors = F.normalize(hs, 2, 1)  # normalize.\n",
    "            fingerprint_vectors = hs\n",
    "\n",
    "        \"\"\"Molecular vector by sum or mean of the fingerprint vectors.\"\"\"\n",
    "        molecular_vectors = self.sum(fingerprint_vectors, molecular_sizes)\n",
    "        # molecular_vectors = self.mean(fingerprint_vectors, molecular_sizes)\n",
    "\n",
    "        return molecular_vectors\n",
    "\n",
    "    \n",
    "class TestModelStruc(nn.Module):\n",
    "    def __init__(self, vocab_size, ddi_adj, ddi_matrix, GNNSet, N_fingerprints, emb_dim=256, device=torch.device('cpu:0')):\n",
    "        super(TestModelStruc, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # pre-embedding\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(vocab_size[i], emb_dim) for i in range(2)])\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "        self.encoders = nn.ModuleList([nn.GRU(emb_dim, emb_dim*2, batch_first=True) for _ in range(2)])\n",
    "        self.query = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4 * emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "        # implicit\n",
    "        self.fraction_linear = nn.Sequential(\n",
    "            nn.Linear(emb_dim, ddi_matrix.shape[1])\n",
    "        )\n",
    "        # self.output = MaskLinear(ddi_matrix.shape[1], vocab_size[2])\n",
    "        self.output = nn.Linear(ddi_matrix.shape[1], vocab_size[2])\n",
    "\n",
    "        # explicit\n",
    "        self.GNN_linear = nn.Linear(emb_dim, vocab_size[2])\n",
    "        self.GNNSet = list(zip(*GNNSet))\n",
    "        self.GNN_emb = MolecularGraphNeuralNetwork(N_fingerprints, emb_dim, layer_hidden=2, device=device).forward(self.GNNSet)\n",
    "        self.GNN_emb_fix = torch.tensor(self.GNN_emb, requires_grad=True)\n",
    "\n",
    "        # graphs\n",
    "        self.tensor_ddi_adj = torch.FloatTensor(ddi_adj).to(device)\n",
    "        self.tensor_ddi_matrix = torch.FloatTensor(ddi_matrix).to(device)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        \"\"\"\n",
    "        def mean_embedding(embedding):\n",
    "            return embedding.mean(dim=1)  # (1,1,dim)\n",
    "\n",
    "        diag_emb = mean_embedding(self.embeddings[0](torch.LongTensor(input[0]).unsqueeze(dim=0).to(self.device))) # (1,dim)\n",
    "        prod_emb = mean_embedding(self.embeddings[1](torch.LongTensor(input[1]).unsqueeze(dim=0).to(self.device))) # (1,dim)\n",
    "        query = self.query(torch.cat([diag_emb, prod_emb], dim=1))\n",
    "        \"\"\"\n",
    "\n",
    "\t# generate medical embeddings and queries\n",
    "        i1_seq = []\n",
    "        i2_seq = []\n",
    "        def mean_embedding(embedding):\n",
    "            return embedding.mean(dim=1).unsqueeze(dim=0)  # (1,1,dim)\n",
    "        for adm in input:\n",
    "            i1 = mean_embedding(self.dropout(self.embeddings[0](torch.LongTensor(adm[0]).unsqueeze(dim=0).to(self.device)))) # (1,1,dim)\n",
    "            i2 = mean_embedding(self.dropout(self.embeddings[1](torch.LongTensor(adm[1]).unsqueeze(dim=0).to(self.device))))\n",
    "            i1_seq.append(i1)\n",
    "            i2_seq.append(i2)\n",
    "        i1_seq = torch.cat(i1_seq, dim=1) #(1,seq,dim)\n",
    "        i2_seq = torch.cat(i2_seq, dim=1) #(1,seq,dim)\n",
    "\n",
    "        o1, h1 = self.encoders[0](\n",
    "            i1_seq\n",
    "        ) # o1:(1, seq, dim*2) hi:(1,1,dim*2)\n",
    "        o2, h2 = self.encoders[1](\n",
    "            i2_seq\n",
    "        )\n",
    "        patient_representations = torch.cat([o1, o2], dim=-1).squeeze(dim=0) # (seq, dim*4)\n",
    "        query = self.query(patient_representations)[-1:, :] # (seq, dim)\n",
    "\n",
    "\t# implicit GNN molecule structure\n",
    "        att = F.softmax(torch.mm(query, self.GNN_emb_fix.t()), dim=-1)  # (1, size)\n",
    "        GNN_out = self.GNN_linear(torch.mm(att, self.GNN_emb_fix))  # (1, dim)\n",
    "        \n",
    "\t# explicit mask molecule structure\n",
    "        # fraction_out = self.output(self.fraction_linear(query), self.tensor_ddi_matrix.t())\n",
    "        fraction_out = self.output(self.fraction_linear(query))\n",
    "\n",
    "        # result = torch.mul(fraction_out, GNN_out)\n",
    "        result = fraction_out\n",
    "        \n",
    "        neg_pred_prob = F.sigmoid(result)\n",
    "        neg_pred_prob = neg_pred_prob.t() * neg_pred_prob  # (voc_size, voc_size)\n",
    "        batch_neg = neg_pred_prob.mul(self.tensor_ddi_adj).sum()\n",
    "\n",
    "        return result, batch_neg\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights.\"\"\"\n",
    "        initrange = 0.1\n",
    "        for item in self.embeddings:\n",
    "            item.weight.data.uniform_(-initrange, initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_name = '/home/chaoqiy2/TEMP/GAMENet/code2/saved/emb_LR_drug_molecule/Epoch_39_JA_0.5123_DDI_0.0597.model'.format(model_name)\n",
    "\n",
    "model = TestModelStruc(voc_size, ddi_adj, ddi_matrix, GNNSet, N_fingerprint, emb_dim=256, device=device)\n",
    "model.load_state_dict(torch.load(open(resume_name, 'rb')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
